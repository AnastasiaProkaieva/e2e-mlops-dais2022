custom:

  # Global MLflow params for each environment
  mlflow-params-dev: &mlflow-params-dev
    model_train_experiment_path: '/Users/niall.turbitt@databricks.com/e2e_mlops_dev'
    model_registry_name: 'e2e_mlops_telco_churn_dev'
    model_deploy_experiment_path: '/Users/niall.turbitt@databricks.com/e2e_mlops_deployment_dev'

  mlflow-params-prod: &mlflow-params-prod
    model_train_experiment_path: '/Users/niall.turbitt@databricks.com/e2e_mlops_prod'
    model_registry_name: 'e2e_mlops_telco_churn_prod'
    model_deploy_experiment_path: '/Users/niall.turbitt@databricks.com/e2e_mlops_deployment_prod'

  # Global data params for each environment
  data-params-dev: &data-params-dev
    # Feature Store params
    feature_store_database_name: 'e2e_mlops_dev'
    feature_store_table_name: 'churn_features'
    feature_store_table_primary_keys: 'customerID'
    feature_store_table_description: 'These features are derived from the field_demos_retail.bronze_customers table in the lakehouse.  We created dummy variables for the categorical columns, cleaned up their names, and added a boolean flag for whether the customer churned or not.  No aggregations were performed.'
    # Labels table params
    labels_table_database_name: 'e2e_mlops_dev'
    labels_table_name: 'churn_labels'
    labels_table_label_col: 'churn'
    labels_table_dbfs_path: 'dbfs:/tmp/e2e_mlops_dev/churn_labels.delta'
    # Predictions table params
    predictions_table_dbfs_path: 'dbfs:/tmp/e2e_mlops_dev/churn_predictions.delta'
    predictions_table_database_name: 'e2e_mlops_dev'
    predictions_table_name: 'churn_predictions'

  data-params-prod: &data-params-prod
    # Feature Store params
    feature_store_database_name: 'e2e_mlops_prod'
    feature_store_table_name: 'churn_features'
    feature_store_table_primary_keys: 'customerID'
    feature_store_table_description: 'These features are derived from the field_demos_retail.bronze_customers table in the lakehouse.  We created dummy variables for the categorical columns, cleaned up their names, and added a boolean flag for whether the customer churned or not.  No aggregations were performed.'
    # Labels table params
    labels_table_database_name: 'e2e_mlops_prod'
    labels_table_name: 'churn_labels'
    labels_table_label_col: 'churn'
    labels_table_dbfs_path: 'dbfs:/tmp/e2e_mlops_prod/churn_labels.delta'
    # Predictions table params
    predictions_table_dbfs_path: 'dbfs:/tmp/e2e_mlops_prod/churn_predictions.delta'
    predictions_table_database_name: 'e2e_mlops_prod'
    predictions_table_name: 'churn_predictions'

  # Cluster configs for each environment
  default-cluster-spec: &default-cluster-spec
    spark_version: '10.5.x-cpu-ml-scala2.12'
    node_type_id: 'i3.xlarge'
    driver_node_type_id: 'i3.xlarge'
    num_workers: 1

  dev-cluster-config: &dev-cluster-config
    new_cluster:
      <<: *default-cluster-spec
      spark_env_vars:
        DEPLOYMENT_ENV: dev
        <<: [*mlflow-params-dev, *data-params-dev]

  staging-cluster-config: &staging-cluster-config
    new_cluster:
      <<: *default-cluster-spec
      spark_env_vars:
        DEPLOYMENT_ENV: staging

  prod-cluster-config: &prod-cluster-config
    new_cluster:
      <<: *default-cluster-spec
      spark_env_vars:
        DEPLOYMENT_ENV: prod
        <<: [*mlflow-params-prod, *data-params-prod]

# Databricks Jobs definitions
# please note that we're using FUSE reference for config file, hence we're going to load this file using its local FS path
environments:

  dev:
    strict_path_adjustment_policy: true
    jobs:
      - name: 'demo-setup'
        <<: *dev-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/demo_setup_job.py'
          parameters: [ '--conf-file', 'file:fuse://conf/job_configs/demo_setup.yml' ]
      - name: 'feature-table-creation'
        <<: *dev-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/feature_table_creator_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/feature_table_creation.yml']
      - name: 'model-train'
        <<:
          - *dev-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_train_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_train.yml']
      - name: 'model-deployment'
        <<:
          - *dev-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_deployment_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_deployment.yml']
      - name: 'model-inference-batch'
        <<:
          - *dev-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_inference_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_inference_batch.yml']
      - name: 'sample-integration-test'
        <<:
          - *dev-cluster-config
        spark_python_task:
          python_file: 'file://tests/integration/sample_test.py'
          parameters: [ '--conf-file', 'file:fuse://conf/job_configs/sample_test.yml' ]

  staging:
    strict_path_adjustment_policy: true
    jobs:
      - name: 'sample-integration-test'
        <<:
          - *staging-cluster-config
        spark_python_task:
          python_file: 'file://tests/integration/sample_test.py'
          parameters: [ '--conf-file', 'file:fuse://conf/job_configs/sample_test.yml' ]

  prod:
    strict_path_adjustment_policy: true
    jobs:
      - name: 'demo-setup'
        <<: *prod-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/demo_setup_job.py'
          parameters: [ '--conf-file', 'file:fuse://conf/job_configs/demo_setup.yml' ]
      - name: 'initial-model-train-register'
        tasks:
          - task_key: 'demo-setup'
            <<:
              - *prod-cluster-config
            spark_python_task:
              python_file: 'file://telco_churn/jobs/demo_setup_job.py'
              parameters: [ '--conf-file', 'file:fuse://conf/job_configs/demo_setup.yml' ]
          - task_key: 'feature-table-creation'
            <<: *prod-cluster-config
            depends_on:
              - task_key: 'demo-setup'
            spark_python_task:
              python_file: 'file://telco_churn/jobs/feature_table_creator_job.py'
              parameters: ['--conf-file', 'file:fuse://conf/job_configs/feature_table_creation.yml']
          - task_key: 'model-train'
            <<: *prod-cluster-config
            depends_on:
              - task_key: 'demo-setup'
              - task_key: 'feature-table-creation'
            spark_python_task:
              python_file: 'file://telco_churn/jobs/model_train_job.py'
              parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_train.yml']
      - name: 'model-train'
        <<:
          - *prod-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_train_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_train.yml']
      - name: 'model-deployment'
        <<:
          - *prod-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_deployment_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_deployment.yml']
      - name: 'model-inference-batch'
        <<:
          - *prod-cluster-config
        spark_python_task:
          python_file: 'file://telco_churn/jobs/model_inference_job.py'
          parameters: ['--conf-file', 'file:fuse://conf/job_configs/model_inference_batch.yml']